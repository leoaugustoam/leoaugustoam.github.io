:souce-highlighter: pygments
:steam:


= Processamento Digital de Imagens

Leonardo Augusto de Aquino Marques <leoaugustoam@gmail.com>

== Unidade 1

=== Manipulando pixels em uma imagem
Utilizando o programa https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/codigos/pixels.cpp[exemplo/pixels.cpp] como referência, foi implementado o programa regions.cpp. Esse programa solicita ao usuário as coordenadas x e y de dois pontos P1 e P2, localizados dentro dos limites do tamanho da imagem e exibir o que lhe for fornecida. Entretanto, a região definida pelo retângulo de vértices opostos definidos pelos pontos P1 e P2 será exibida com o negativo da imagem na região correspondente.

Inicialmente, a imagem é carregada e suas dimensões são verificadas, de modo a mostrar ao usuario quais pixels ele pode modificar. Logo apos, deve ser digitado as cordenadas do ponto 1 (X1 e Y1) e ponto 2 (X2 e Y2), para que a area definida pelo retângulo destes vertices (P1 e P2) seja negativada, feito isto, a imagem é percorrida por 2 laços em que negativa a imagem na area definida, fazendo com que cada pixel, seja invertido (255 - valor_atual_do_pixel).


 
[source,cpp]
-----------------
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main(int, char**) {
	
	int x1,x2,y1,y2;
	Mat image;
	Size size;
	
	image = cv::imread("foto.jpg", CV_LOAD_IMAGE_GRAYSCALE);

	if(!image.data){
    		cout << "Imagem não abriu" << endl;
	}

	//imshow("image", image);
	size = image.size();
	
	cout << "Sua imagem tem "<< size.height <<"x" << size.width << endl;
	cout << "Digite os pontos da area que deseja negativar!\nPrimeiro X1:\n";
	cin >> x1;
	cout << "Agora Y1\n";
	cin >> y1;
	cout << "Agora X2\n";
	cin >> x2;
	cout << "Agora Y2\n";
	cin >> y2;

	for(int x=x1; x<=x2; x++) {
		for(int y=y1; y<=y2; y++) {
			image.at<uchar>(x,y)= 255 - image.at<uchar>(x,y);
		}
	}
	//namedWindow("Trab 1",WINDOW_AUTOSIZE);	
	imshow("Trabalho 1", image);
	waitKey();
  
  return 0;
}

-----------------

.Foto original
[#img-sunset]
[caption="Figure 1: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/biel.png?raw=true[Sunset,256,256]

.Foto modificada
[#img-sunset]
[caption="Figure 2: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/negativo.png?raw=true[Sunset,256,256]

=== Invertendo regiões
O programa deve trocar os quadrantes em diagonal na imagem. Inicialmente como podemos ver no código, a imagem é dividida em 4 partes iguais (como sabemos que a imagem tem 256x256, a imagem é cortada nos pontos {(0,0),(128,0),(0,128),(128,128)}), e construimos uma nova imagem colando em cada quadrante, uma parte cortada anteriormente.


 
[source,cpp]
-----------------
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int, char**){
  Mat image, image2, p1, p2, p3, p4;
  int width, height;

  image = imread("biel.png",CV_LOAD_IMAGE_GRAYSCALE);
  image2 = imread("biel.png",CV_LOAD_IMAGE_GRAYSCALE);

  width  = image.size().width;
  height = image.size().height;

  p1 = image(Rect(0,0,(width/2),(height/2)));
  p2 = image(Rect((width/2),0,(width/2),(height/2)));
  p3 = image(Rect(0,(height/2),(width/2),(height/2)));
  p4 = image(Rect((width/2),(height/2),(width/2),(height/2)));

  imshow("Original", image);
  waitKey();

  p1.copyTo(image2(Rect((width/2),(height/2),(width/2),(height/2))));
  p2.copyTo(image2(Rect(0,(height/2),(width/2),(height/2))));
  p3.copyTo(image2(Rect((width/2),0,(width/2),(height/2))));
  p4.copyTo(image2(Rect(0,0,(width/2),(height/2))));

  imshow("Imagem trocada", image2);
  imwrite("imagemtrocada.png", image2);
  waitKey();

  return 0;
}



-----------------

.Exemplo do código acima
[#img-sunset]
[caption="Figure 3: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/bieltrocado2.png?raw=true[Sunset,256,256]


Modificando os quadrantes da colagem:


[source,cpp]
-----------------

 p1.copyTo(image2(Rect((width/2),(height/2),(width/2),(height/2))));
  p2.copyTo(image2(Rect((width/2),0,(width/2),(height/2))));
  p3.copyTo(image2(Rect(0,(height/2),(width/2),(height/2))));
  p4.copyTo(image2(Rect(0,0,(width/2),(height/2))));


-----------------

.Exemplo do código acima com modificação dos quadrantes
[#img-sunset]
[caption="Figure 4: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/bieltrocado.png?raw=true[Sunset,256,256]











=== Preenchendo regiões
O primeiro problema é referente caso exista mais de 255 objetos na cena, em que o problema de rotulação fica comprometido, e isto ocorre devido a quantidade de bits que são usados na imagem, no caso 8bits, assim, obtendo 256 tons de cinza disponivel. E para resolver este problema, poderia aumentar a quantidade de bits para representar cada cor, por exemplo se tivesse 10 bits, poderia ter ate 1024 tons de cinza na imagem, considerando a imagem sempre em tom de cinza. 

A segunda problematica é em relaçao a contagem de regiões com ou sem buracos internos que existam na cena, retirando as que tocam na borda, para tanto, é necessario primeiramente remover todas as regiões que tocam a borda, para isso, é aplicado o floodFill em todas as regioes q tocam as linhas ou colunas da borda, e para ficar facil identificar as regiões com buracos, mudamos o o tom de cinza do fundo da imagem(floodfill no ponto (0,0)), então para o tom de cinza original, significa o buraco de alguma area da cena, então é possivel aplicar o floodfill para diferenciar das demais, e para as areas restantes, são as areas sem furo.

[source,cpp]
-----------------

#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;
int main(int argc, char** argv) {
	Mat image;
	int width, height;
	int comfuro, semfuro, total;
	CvPoint p;
	image = imread("bolhas.png", CV_LOAD_IMAGE_GRAYSCALE);
	if (!image.data) {
		cout << "Erro ao carregar imagem, pfvr, verificar.\n";
	}
	width = image.size().width;
	height = image.size().height;
	p.x = 0;
	p.y = 0;
	for (int i = 0; i<height; i++) {
		for (int j = 0; j<width; j++) {
			if (i == 0 || i == 255 || j == 0 || j == 255) {
				if (image.at<uchar>(i, j) != 0) {
					p.x = j;
					p.y = i;
					floodFill(image, p, 0);
				}
			}
		}
	}
	p.x = 0;
	p.y = 0;
	floodFill(image, p, 1);
	comfuro = 0;
	for (int i = 0; i<height; i++) {
		for (int j = 0; j<width; j++) {
			if (image.at<uchar>(i, j) == 0) {
				if (image.at<uchar>(i, j - 1) == 255) {
					comfuro++;
					p.y = i;
					p.x = j - 1;
					floodFill(image, p, 100);
				}
			}
		}
	}
	semfuro = 0;
	for (int i = 0; i<height; i++) {
		for (int j = 0; j<width; j++) {
			if (image.at<uchar>(i, j) == 255) {
				semfuro++;
				p.x = j;
				p.y = i;
				floodFill(image, p, 200);
			}
		}
	}
	cout << "Numero de bolhas com buracos:" << comfuro << endl;
	cout << "Numero de bolhas sem buracos:" << semfuro << endl;
	imshow("image", image);
	imwrite("labeling.png", image);
	waitKey();
	return 0;
} 	
-----------------

.Resultado obtido
[#img-sunset]
[caption="Figure 5: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/labeling.png?raw=true[Sunset,256,256]


=== Manipulação de histogramas

Como mostrado anteriormente e analisando o programa histogram.cpp, adaptamos o codigo de forma a equalizar a imagem capturada, de grosso modo, o histograma realiza a contagem de ocorrência de cada um dos possiveis tons de uma imagem, e a equalização é uma ação para mudar a distribuição de valores de modo a reduzir as diferenças acentuadas da imagem, e assim acentuando detalhes não visíveis anteriormente.
[source,cpp]
-----------------
#include <iostream>
#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;
int main(int argc, char** argv) {
	Mat image, equalized;
	int width, height;
	VideoCapture cap;
	vector<Mat> planes, c;
	Mat histR, histG, histB;
	int nbins = 64;
	float range[] = { 0, 256 };
	const float *histrange = { range };
	bool uniform = true;
	bool acummulate = false;

	cap.open(1);
	if (!cap.isOpened()) {
		cout << "cameras indisponiveis";
		return -1;
	}

	width = cap.get(CV_CAP_PROP_FRAME_WIDTH);
	height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

	//cout << "largura = " << width << endl;
	//cout << "altura  = " << height << endl;

	int histw = nbins, histh = nbins / 2;
	Mat histImgR(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat histImgG(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat histImgB(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	while (1) {
		cap >> image;
		split(image, planes);
		calcHist(&planes[0], 1, 0, Mat(), histR, 1,
			&nbins, &histrange,
			uniform, acummulate);
		calcHist(&planes[1], 1, 0, Mat(), histG, 1,
			&nbins, &histrange,
			uniform, acummulate);
		calcHist(&planes[2], 1, 0, Mat(), histB, 1,
			&nbins, &histrange,
			uniform, acummulate);
		normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
		normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
		normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());
		histImgR.setTo(Scalar(0));
		histImgG.setTo(Scalar(0));
		histImgB.setTo(Scalar(0));
		for (int i = 0; i<nbins; i++) {
			line(histImgR,
				Point(i, histh),
				Point(i, histh - cvRound(histR.at<float>(i))),
				Scalar(0, 0, 255), 1, 8, 0);
			line(histImgG,
				Point(i, histh),
				Point(i, histh - cvRound(histG.at<float>(i))),
				Scalar(0, 255, 0), 1, 8, 0);
			line(histImgB,
				Point(i, histh),
				Point(i, histh - cvRound(histB.at<float>(i))),
				Scalar(255, 0, 0), 1, 8, 0);
		}
		split(image, c);
		equalizeHist(c[0], c[0]);
		equalizeHist(c[1], c[1]);
		equalizeHist(c[2], c[2]);
		merge(c, equalized);
		histImgR.copyTo(image(Rect(0, 0, nbins, histh)));
		histImgG.copyTo(image(Rect(0, histh, nbins, histh)));
		histImgB.copyTo(image(Rect(0, 2 * histh, nbins, histh)));
		imshow("image", image);
		imshow("equalized", equalized);
		if (waitKey(30) >= 0) break;
	}
	return 0;
}


} 	
-----------------

.Resultado obtido em diferentes iluminações
[#img-sunset]
[caption="Figure 6: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/res1.jpg?raw=true[Sunset,512,256]

.Resultado obtido em diferentes iluminações
[#img-sunset]
[caption="Figure 7: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/res2.png?raw=true[Sunset,512,256]

.Resultado obtido em diferentes iluminações
[#img-sunset]
[caption="Figure 8: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/resultado.png?raw=true[Sunset,512,256]




=== Detecção de movimento

O detector de movimento é criado analisando um dos canais do histograma, neste caso foi analisado o canal RED. É analisado o histograma da imagem capturada no momento e em um momento anterior, então é somado todos os valores do histograma do canal observado em ambas as imagens, com isto, é comparado as 2 somas e se ultrapassar um limiar pre-definido, é impresso na tela "movimento detectado". Como a imagem é capturada em um instante muito proximo uma da outra, não se pode colocar um limiar muito alto pois se não é apenas detectado apenas um movimento muito rápido, e um limiar pequeno, qualquer simples movimento é detectado, entao este limiar irá definir a precisão do movimento que se deseja alcançar.

[source,cpp]
-----------------
#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;
int main(int argc, char** argv) {

	Mat image;
	int width, height;
	VideoCapture cap;
	vector<Mat> planes;
	Mat histR, histG, histB;

	int nbins = 64;
	float range[] = { 0, 256 };
	int sum, sumA;
	const float *histrange = { range };
	bool uniform = true;
	bool acummulate = false;
	cap.open(1);
	if (!cap.isOpened()) {
		cout << "cameras indisponiveis";
		return -1;
	}

	width = cap.get(CV_CAP_PROP_FRAME_WIDTH);
	height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);
	//cout << "largura = " << width << endl;
	//cout << "altura  = " << height << endl;
	int histw = nbins, histh = nbins / 2;
	Mat histImgR(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat histImgG(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat histImgB(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat Ranterior(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	while (1) {
		cap >> image;
		split(image, planes);
		calcHist(&planes[0], 1, 0, Mat(), histR, 1,
			&nbins, &histrange,
			uniform, acummulate);
		calcHist(&planes[1], 1, 0, Mat(), histG, 1,
			&nbins, &histrange,
			uniform, acummulate);
		calcHist(&planes[2], 1, 0, Mat(), histB, 1,
			&nbins, &histrange,
			uniform, acummulate);
		normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
		normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
		normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());
		histImgR.setTo(Scalar(0));
		histImgG.setTo(Scalar(0));
		histImgB.setTo(Scalar(0));
		for (int i = 0; i<nbins; i++) {
			line(histImgR,
				Point(i, histh),
				Point(i, histh - cvRound(histR.at<float>(i))),
				Scalar(0, 0, 255), 1, 8, 0);
			line(histImgG,
				Point(i, histh),
				Point(i, histh - cvRound(histG.at<float>(i))),
				Scalar(0, 255, 0), 1, 8, 0);
			line(histImgB,
				Point(i, histh),
				Point(i, histh - cvRound(histB.at<float>(i))),
				Scalar(255, 0, 0), 1, 8, 0);
		}
		histImgR.copyTo(image(Rect(0, 0, nbins, histh)));
		histImgG.copyTo(image(Rect(0, histh, nbins, histh)));
		histImgB.copyTo(image(Rect(0, 2 * histh, nbins, histh)));

		for (int i = 0; i<histh; i++) {
			for (int j = 0; j<histw; j++) {
				sum = sum + histImgR.at<uchar>(i, j);
				sumA = sumA + Ranterior.at<uchar>(i, j);
			}
		}

		if (abs(sum - sumA) >= 8000) {
			putText(image, "Movimento detectado!", cvPoint(15, 470),
				FONT_HERSHEY_COMPLEX, 1, cvScalar(0, 255, 255), 1, CV_AA);
		}

		imshow("image", image);
		if (waitKey(30) >= 0) break;
		Ranterior = histImgR.clone();
		sum = 0;
		sumA = 0;
	}
	return 0;
}

}


} 	
-----------------

.Movimento detectado
[#img-sunset]
[caption="Figure 9: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/movimento.png?raw=true[Sunset,315,256]




=== Filtragem no domínio espacial I

Baseado no exemplo filtroespacial.cpp, foi implementado uma opção no menu para o filtro laplaciano do gaussiano, bem como sua matriz de convolução. 

[source,cpp]
-----------------

#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;
void printmask(Mat &m) {
	for (int i = 0; i<m.size().height; i++) {
		for (int j = 0; j<m.size().width; j++) {
			cout << m.at<float>(i, j) << ",";
		}
		cout << endl;
	}
}
void menu() {
	cout << "\npressione a tecla para ativar o filtro: \n"
		"a - calcular modulo\n"
		"m - media\n"
		"g - gauss\n"
		"v - vertical\n"
		"h - horizontal\n"
		"l - laplaciano\n"
		"p - laplaciano do gaussiano\n"
		"esc - sair\n";
}
int main(int argvc, char** argv) {
	VideoCapture video;
	float media[] = { 1,1,1,
		1,1,1,
		1,1,1 };
	float gauss[] = { 1,2,1,
		2,4,2,
		1,2,1 };
	float horizontal[] = { -1,0,1,
		-2,0,2,
		-1,0,1 };
	float vertical[] = { -1,-2,-1,
		0,0,0,
		1,2,1 };
	float laplacian[] = { 0,-1,0,
		-1,4,-1,
		0,-1,0 };
	float laplgauss[] = { 0,0,1,0,0,
		0,1,2,1,0,
		1,2,-16,2,1,
		0,1,2,1,0,
		0,0,1,0,0 };
	Mat cap, frame, frame32f, frameFiltered;
	Mat mask(3, 3, CV_32F), mask1;
	Mat result, result1;
	double width, height, min, max;
	int absolut;
	char key;
	video.open(1);
	if (!video.isOpened())
		return -1;
	width = video.get(CV_CAP_PROP_FRAME_WIDTH);
	height = video.get(CV_CAP_PROP_FRAME_HEIGHT);
	std::cout << "largura=" << width << "\n";;
	std::cout << "altura =" << height << "\n";;
	namedWindow("filtroespacial", 1);
	mask = Mat(3, 3, CV_32F, media);
	scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
	swap(mask, mask1);
	absolut = 1; // calcs abs of the image
	menu();
	for (;;) {
		video >> cap;
		cvtColor(cap, frame, CV_BGR2GRAY);
		flip(frame, frame, 1);
		imshow("original", frame);
		frame.convertTo(frame32f, CV_32F);
		filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1, 1), 0);
		if (absolut) {
			frameFiltered = abs(frameFiltered);
		}
		frameFiltered.convertTo(result, CV_8U);
		imshow("filtroespacial", result);
		key = (char)waitKey(10);
		if (key == 27) break; // esc pressed!
		switch (key) {
		case 'a':
			menu();
			absolut = !absolut;
			break;
		case 'm':
			menu();
			mask = Mat(3, 3, CV_32F, media);
			scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
			mask = mask1;
			printmask(mask);
			break;
		case 'g':
			menu();
			mask = Mat(3, 3, CV_32F, gauss);
			scaleAdd(mask, 1 / 16.0, Mat::zeros(3, 3, CV_32F), mask1);
			mask = mask1;
			printmask(mask);
			break;
		case 'h':
			menu();
			mask = Mat(3, 3, CV_32F, horizontal);
			printmask(mask);
			break;
		case 'v':
			menu();
			mask = Mat(3, 3, CV_32F, vertical);
			printmask(mask);
			break;
		case 'l':
			menu();
			mask = Mat(3, 3, CV_32F, laplacian);
			printmask(mask);
			break;
		case 'p':
			menu();
			mask = Mat(5, 5, CV_32F, laplgauss);
			printmask(mask);
			break;
		default:
			break;
		}
	}
	return 0;
}

} 	
-----------------

.Imagem Original
[#img-sunset]
[caption="Figure x: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/foto%20flamengo%20original.jpg?raw=true[Sunset,300,300]

.Filtro Horizontal
[#img-sunset]
[caption="Figure 10: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/filtro%20horizontal.jpg?raw=true[Sunset,300,300]


.Filtro gauss
[#img-sunset]
[caption="Figure x: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/gaus.jpg?raw=true[Sunset,300,300]


.Filtro laplaciano
[#img-sunset]
[caption="Figure x: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/laplaciano.jpg?raw=true[Sunset,300,300]



.Filtro laplaciano-gaussiano
[#img-sunset]
[caption="Figure x: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/laplaciano%20de%20gaussiano.jpg.jpg?raw=true[Sunset,300,300]


