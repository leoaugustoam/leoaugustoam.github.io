:toc: left
:numbered:
:source-highlighter: pygments
:stem:
:lang: pt-BR


= Processamento Digital de Imagens

Leonardo Augusto de Aquino Marques <leoaugustoam@gmail.com> ; Caio José Borba Vilar Guimarães <caio.bvilar@dca.ufrn.br>

== Unidade 1

=== Manipulando pixels em uma imagem
Utilizando o programa https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/codigos/pixels.cpp[exemplo/pixels.cpp] como referência, foi implementado o programa regions.cpp. Esse programa solicita ao usuário as coordenadas x e y de dois pontos P1 e P2, localizados dentro dos limites do tamanho da imagem e exibir o que lhe for fornecida. Entretanto, a região definida pelo retângulo de vértices opostos definidos pelos pontos P1 e P2 será exibida com o negativo da imagem na região correspondente.

Inicialmente, a imagem é carregada e suas dimensões são verificadas, de modo a mostrar ao usuario quais pixels ele pode modificar. Logo apos, deve ser digitado as cordenadas do ponto 1 (X1 e Y1) e ponto 2 (X2 e Y2), para que a area definida pelo retângulo destes vertices (P1 e P2) seja negativada, feito isto, a imagem é percorrida por 2 laços em que negativa a imagem na area definida, fazendo com que cada pixel, seja invertido (255 - valor_atual_do_pixel).


 
[source,cpp]
-----------------
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main(int, char**) {
	
	int x1,x2,y1,y2;
	Mat image;
	Size size;
	
	image = cv::imread("foto.jpg", CV_LOAD_IMAGE_GRAYSCALE);

	if(!image.data){
    		cout << "Imagem não abriu" << endl;
	}

	//imshow("image", image);
	size = image.size();
	
	cout << "Sua imagem tem "<< size.height <<"x" << size.width << endl;
	cout << "Digite os pontos da area que deseja negativar!\nPrimeiro X1:\n";
	cin >> x1;
	cout << "Agora Y1\n";
	cin >> y1;
	cout << "Agora X2\n";
	cin >> x2;
	cout << "Agora Y2\n";
	cin >> y2;

	for(int x=x1; x<=x2; x++) {
		for(int y=y1; y<=y2; y++) {
			image.at<uchar>(x,y)= 255 - image.at<uchar>(x,y);
		}
	}
	//namedWindow("Trab 1",WINDOW_AUTOSIZE);	
	imshow("Trabalho 1", image);
	waitKey();
  
  return 0;
}

-----------------

.Foto original
[#img-sunset]
[caption="Figure 1: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/biel.png?raw=true[Sunset,256,256]

.Foto modificada
[#img-sunset]
[caption="Figure 2: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/negativo.png?raw=true[Sunset,256,256]

=== Invertendo regiões
O programa deve trocar os quadrantes em diagonal na imagem. Inicialmente como podemos ver no código, a imagem é dividida em 4 partes iguais (como sabemos que a imagem tem 256x256, a imagem é cortada nos pontos {(0,0),(128,0),(0,128),(128,128)}), e construimos uma nova imagem colando em cada quadrante, uma parte cortada anteriormente.


 
[source,cpp]
-----------------
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int, char**){
  Mat image, image2, p1, p2, p3, p4;
  int width, height;

  image = imread("biel.png",CV_LOAD_IMAGE_GRAYSCALE);
  image2 = imread("biel.png",CV_LOAD_IMAGE_GRAYSCALE);

  width  = image.size().width;
  height = image.size().height;

  p1 = image(Rect(0,0,(width/2),(height/2)));
  p2 = image(Rect((width/2),0,(width/2),(height/2)));
  p3 = image(Rect(0,(height/2),(width/2),(height/2)));
  p4 = image(Rect((width/2),(height/2),(width/2),(height/2)));

  imshow("Original", image);
  waitKey();

  p1.copyTo(image2(Rect((width/2),(height/2),(width/2),(height/2))));
  p2.copyTo(image2(Rect(0,(height/2),(width/2),(height/2))));
  p3.copyTo(image2(Rect((width/2),0,(width/2),(height/2))));
  p4.copyTo(image2(Rect(0,0,(width/2),(height/2))));

  imshow("Imagem trocada", image2);
  imwrite("imagemtrocada.png", image2);
  waitKey();

  return 0;
}



-----------------

.Exemplo do código acima
[#img-sunset]
[caption="Figure 3: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/bieltrocado2.png?raw=true[Sunset,256,256]


Modificando os quadrantes da colagem:


[source,cpp]
-----------------

 p1.copyTo(image2(Rect((width/2),(height/2),(width/2),(height/2))));
  p2.copyTo(image2(Rect((width/2),0,(width/2),(height/2))));
  p3.copyTo(image2(Rect(0,(height/2),(width/2),(height/2))));
  p4.copyTo(image2(Rect(0,0,(width/2),(height/2))));


-----------------

.Exemplo do código acima com modificação dos quadrantes
[#img-sunset]
[caption="Figure 4: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/bieltrocado.png?raw=true[Sunset,256,256]











=== Preenchendo regiões
O primeiro problema é referente caso exista mais de 255 objetos na cena, em que o problema de rotulação fica comprometido, e isto ocorre devido a quantidade de bits que são usados na imagem, no caso 8bits, assim, obtendo 256 tons de cinza disponivel. E para resolver este problema, poderia aumentar a quantidade de bits para representar cada cor, por exemplo se tivesse 10 bits, poderia ter ate 1024 tons de cinza na imagem, considerando a imagem sempre em tom de cinza. 

A segunda problematica é em relaçao a contagem de regiões com ou sem buracos internos que existam na cena, retirando as que tocam na borda, para tanto, é necessario primeiramente remover todas as regiões que tocam a borda, para isso, é aplicado o floodFill em todas as regioes q tocam as linhas ou colunas da borda, e para ficar facil identificar as regiões com buracos, mudamos o o tom de cinza do fundo da imagem(floodfill no ponto (0,0)), então para o tom de cinza original, significa o buraco de alguma area da cena, então é possivel aplicar o floodfill para diferenciar das demais, e para as areas restantes, são as areas sem furo.

[source,cpp]
-----------------

#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;
int main(int argc, char** argv) {
	Mat image;
	int width, height;
	int comfuro, semfuro, total;
	CvPoint p;
	image = imread("bolhas.png", CV_LOAD_IMAGE_GRAYSCALE);
	if (!image.data) {
		cout << "Erro ao carregar imagem, pfvr, verificar.\n";
	}
	width = image.size().width;
	height = image.size().height;
	p.x = 0;
	p.y = 0;
	for (int i = 0; i<height; i++) {
		for (int j = 0; j<width; j++) {
			if (i == 0 || i == 255 || j == 0 || j == 255) {
				if (image.at<uchar>(i, j) != 0) {
					p.x = j;
					p.y = i;
					floodFill(image, p, 0);
				}
			}
		}
	}
	p.x = 0;
	p.y = 0;
	floodFill(image, p, 1);
	comfuro = 0;
	for (int i = 0; i<height; i++) {
		for (int j = 0; j<width; j++) {
			if (image.at<uchar>(i, j) == 0) {
				if (image.at<uchar>(i, j - 1) == 255) {
					comfuro++;
					p.y = i;
					p.x = j - 1;
					floodFill(image, p, 100);
				}
			}
		}
	}
	semfuro = 0;
	for (int i = 0; i<height; i++) {
		for (int j = 0; j<width; j++) {
			if (image.at<uchar>(i, j) == 255) {
				semfuro++;
				p.x = j;
				p.y = i;
				floodFill(image, p, 200);
			}
		}
	}
	cout << "Numero de bolhas com buracos:" << comfuro << endl;
	cout << "Numero de bolhas sem buracos:" << semfuro << endl;
	imshow("image", image);
	imwrite("labeling.png", image);
	waitKey();
	return 0;
} 	
-----------------

.Resultado obtido
[#img-sunset]
[caption="Figure 5: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/labeling.png?raw=true[Sunset,256,256]


=== Manipulação de histogramas

Como mostrado anteriormente e analisando o programa histogram.cpp, adaptamos o codigo de forma a equalizar a imagem capturada, de grosso modo, o histograma realiza a contagem de ocorrência de cada um dos possiveis tons de uma imagem, e a equalização é uma ação para mudar a distribuição de valores de modo a reduzir as diferenças acentuadas da imagem, e assim acentuando detalhes não visíveis anteriormente.
[source,cpp]
-----------------
#include <iostream>
#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;
int main(int argc, char** argv) {
	Mat image, equalized;
	int width, height;
	VideoCapture cap;
	vector<Mat> planes, c;
	Mat histR, histG, histB;
	int nbins = 64;
	float range[] = { 0, 256 };
	const float *histrange = { range };
	bool uniform = true;
	bool acummulate = false;

	cap.open(1);
	if (!cap.isOpened()) {
		cout << "cameras indisponiveis";
		return -1;
	}

	width = cap.get(CV_CAP_PROP_FRAME_WIDTH);
	height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

	//cout << "largura = " << width << endl;
	//cout << "altura  = " << height << endl;

	int histw = nbins, histh = nbins / 2;
	Mat histImgR(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat histImgG(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat histImgB(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	while (1) {
		cap >> image;
		split(image, planes);
		calcHist(&planes[0], 1, 0, Mat(), histR, 1,
			&nbins, &histrange,
			uniform, acummulate);
		calcHist(&planes[1], 1, 0, Mat(), histG, 1,
			&nbins, &histrange,
			uniform, acummulate);
		calcHist(&planes[2], 1, 0, Mat(), histB, 1,
			&nbins, &histrange,
			uniform, acummulate);
		normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
		normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
		normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());
		histImgR.setTo(Scalar(0));
		histImgG.setTo(Scalar(0));
		histImgB.setTo(Scalar(0));
		for (int i = 0; i<nbins; i++) {
			line(histImgR,
				Point(i, histh),
				Point(i, histh - cvRound(histR.at<float>(i))),
				Scalar(0, 0, 255), 1, 8, 0);
			line(histImgG,
				Point(i, histh),
				Point(i, histh - cvRound(histG.at<float>(i))),
				Scalar(0, 255, 0), 1, 8, 0);
			line(histImgB,
				Point(i, histh),
				Point(i, histh - cvRound(histB.at<float>(i))),
				Scalar(255, 0, 0), 1, 8, 0);
		}
		split(image, c);
		equalizeHist(c[0], c[0]);
		equalizeHist(c[1], c[1]);
		equalizeHist(c[2], c[2]);
		merge(c, equalized);
		histImgR.copyTo(image(Rect(0, 0, nbins, histh)));
		histImgG.copyTo(image(Rect(0, histh, nbins, histh)));
		histImgB.copyTo(image(Rect(0, 2 * histh, nbins, histh)));
		imshow("image", image);
		imshow("equalized", equalized);
		if (waitKey(30) >= 0) break;
	}
	return 0;
}


} 	
-----------------

.Resultado obtido em diferentes iluminações
[#img-sunset]
[caption="Figure 6: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/res1.jpg?raw=true[Sunset,512,256]

.Resultado obtido em diferentes iluminações
[#img-sunset]
[caption="Figure 7: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/res2.png?raw=true[Sunset,512,256]

.Resultado obtido em diferentes iluminações
[#img-sunset]
[caption="Figure 8: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/resultado.png?raw=true[Sunset,512,256]




=== Detecção de movimento

O detector de movimento é criado analisando um dos canais do histograma, neste caso foi analisado o canal RED. É analisado o histograma da imagem capturada no momento e em um momento anterior, então é somado todos os valores do histograma do canal observado em ambas as imagens, com isto, é comparado as 2 somas e se ultrapassar um limiar pre-definido, é impresso na tela "movimento detectado". Como a imagem é capturada em um instante muito proximo uma da outra, não se pode colocar um limiar muito alto pois se não é apenas detectado apenas um movimento muito rápido, e um limiar pequeno, qualquer simples movimento é detectado, entao este limiar irá definir a precisão do movimento que se deseja alcançar.

[source,cpp]
-----------------
#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;
int main(int argc, char** argv) {

	Mat image;
	int width, height;
	VideoCapture cap;
	vector<Mat> planes;
	Mat histR, histG, histB;

	int nbins = 64;
	float range[] = { 0, 256 };
	int sum, sumA;
	const float *histrange = { range };
	bool uniform = true;
	bool acummulate = false;
	cap.open(1);
	if (!cap.isOpened()) {
		cout << "cameras indisponiveis";
		return -1;
	}

	width = cap.get(CV_CAP_PROP_FRAME_WIDTH);
	height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);
	//cout << "largura = " << width << endl;
	//cout << "altura  = " << height << endl;
	int histw = nbins, histh = nbins / 2;
	Mat histImgR(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat histImgG(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat histImgB(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	Mat Ranterior(histh, histw, CV_8UC3, Scalar(0, 0, 0));
	while (1) {
		cap >> image;
		split(image, planes);
		calcHist(&planes[0], 1, 0, Mat(), histR, 1,
			&nbins, &histrange,
			uniform, acummulate);
		calcHist(&planes[1], 1, 0, Mat(), histG, 1,
			&nbins, &histrange,
			uniform, acummulate);
		calcHist(&planes[2], 1, 0, Mat(), histB, 1,
			&nbins, &histrange,
			uniform, acummulate);
		normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
		normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
		normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());
		histImgR.setTo(Scalar(0));
		histImgG.setTo(Scalar(0));
		histImgB.setTo(Scalar(0));
		for (int i = 0; i<nbins; i++) {
			line(histImgR,
				Point(i, histh),
				Point(i, histh - cvRound(histR.at<float>(i))),
				Scalar(0, 0, 255), 1, 8, 0);
			line(histImgG,
				Point(i, histh),
				Point(i, histh - cvRound(histG.at<float>(i))),
				Scalar(0, 255, 0), 1, 8, 0);
			line(histImgB,
				Point(i, histh),
				Point(i, histh - cvRound(histB.at<float>(i))),
				Scalar(255, 0, 0), 1, 8, 0);
		}
		histImgR.copyTo(image(Rect(0, 0, nbins, histh)));
		histImgG.copyTo(image(Rect(0, histh, nbins, histh)));
		histImgB.copyTo(image(Rect(0, 2 * histh, nbins, histh)));

		for (int i = 0; i<histh; i++) {
			for (int j = 0; j<histw; j++) {
				sum = sum + histImgR.at<uchar>(i, j);
				sumA = sumA + Ranterior.at<uchar>(i, j);
			}
		}

		if (abs(sum - sumA) >= 8000) {
			putText(image, "Movimento detectado!", cvPoint(15, 470),
				FONT_HERSHEY_COMPLEX, 1, cvScalar(0, 255, 255), 1, CV_AA);
		}

		imshow("image", image);
		if (waitKey(30) >= 0) break;
		Ranterior = histImgR.clone();
		sum = 0;
		sumA = 0;
	}
	return 0;
}

}


} 	
-----------------

.Movimento detectado
[#img-sunset]
[caption="Figure 9: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/movimento.png?raw=true[Sunset,315,256]




=== Filtragem no domínio espacial I

Baseado no exemplo filtroespacial.cpp, foi implementado uma opção no menu para o filtro laplaciano do gaussiano, bem como sua matriz de convolução. 

[source,cpp]
-----------------

#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;
void printmask(Mat &m) {
	for (int i = 0; i<m.size().height; i++) {
		for (int j = 0; j<m.size().width; j++) {
			cout << m.at<float>(i, j) << ",";
		}
		cout << endl;
	}
}
void menu() {
	cout << "\npressione a tecla para ativar o filtro: \n"
		"a - calcular modulo\n"
		"m - media\n"
		"g - gauss\n"
		"v - vertical\n"
		"h - horizontal\n"
		"l - laplaciano\n"
		"p - laplaciano do gaussiano\n"
		"esc - sair\n";
}
int main(int argvc, char** argv) {
	VideoCapture video;
	float media[] = { 1,1,1,
		1,1,1,
		1,1,1 };
	float gauss[] = { 1,2,1,
		2,4,2,
		1,2,1 };
	float horizontal[] = { -1,0,1,
		-2,0,2,
		-1,0,1 };
	float vertical[] = { -1,-2,-1,
		0,0,0,
		1,2,1 };
	float laplacian[] = { 0,-1,0,
		-1,4,-1,
		0,-1,0 };
	float laplgauss[] = { 0,0,1,0,0,
		0,1,2,1,0,
		1,2,-16,2,1,
		0,1,2,1,0,
		0,0,1,0,0 };
	Mat cap, frame, frame32f, frameFiltered;
	Mat mask(3, 3, CV_32F), mask1;
	Mat result, result1;
	double width, height, min, max;
	int absolut;
	char key;
	video.open(1);
	if (!video.isOpened())
		return -1;
	width = video.get(CV_CAP_PROP_FRAME_WIDTH);
	height = video.get(CV_CAP_PROP_FRAME_HEIGHT);
	std::cout << "largura=" << width << "\n";;
	std::cout << "altura =" << height << "\n";;
	namedWindow("filtroespacial", 1);
	mask = Mat(3, 3, CV_32F, media);
	scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
	swap(mask, mask1);
	absolut = 1; // calcs abs of the image
	menu();
	for (;;) {
		video >> cap;
		cvtColor(cap, frame, CV_BGR2GRAY);
		flip(frame, frame, 1);
		imshow("original", frame);
		frame.convertTo(frame32f, CV_32F);
		filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1, 1), 0);
		if (absolut) {
			frameFiltered = abs(frameFiltered);
		}
		frameFiltered.convertTo(result, CV_8U);
		imshow("filtroespacial", result);
		key = (char)waitKey(10);
		if (key == 27) break; // esc pressed!
		switch (key) {
		case 'a':
			menu();
			absolut = !absolut;
			break;
		case 'm':
			menu();
			mask = Mat(3, 3, CV_32F, media);
			scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
			mask = mask1;
			printmask(mask);
			break;
		case 'g':
			menu();
			mask = Mat(3, 3, CV_32F, gauss);
			scaleAdd(mask, 1 / 16.0, Mat::zeros(3, 3, CV_32F), mask1);
			mask = mask1;
			printmask(mask);
			break;
		case 'h':
			menu();
			mask = Mat(3, 3, CV_32F, horizontal);
			printmask(mask);
			break;
		case 'v':
			menu();
			mask = Mat(3, 3, CV_32F, vertical);
			printmask(mask);
			break;
		case 'l':
			menu();
			mask = Mat(3, 3, CV_32F, laplacian);
			printmask(mask);
			break;
		case 'p':
			menu();
			mask = Mat(5, 5, CV_32F, laplgauss);
			printmask(mask);
			break;
		default:
			break;
		}
	}
	return 0;
}

} 	
-----------------

.Imagem Original
[#img-sunset]
[caption="Figure 10: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/foto%20flamengo%20original.jpg?raw=true[Sunset,300,300]

.Filtro Horizontal
[#img-sunset]
[caption="Figure 11: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/filtro%20horizontal.jpg?raw=true[Sunset,300,300]


.Filtro gauss
[#img-sunset]
[caption="Figure 12: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/gaus.jpg?raw=true[Sunset,300,300]


.Filtro laplaciano
[#img-sunset]
[caption="Figure 13: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/laplaciano.jpg?raw=true[Sunset,300,300]



.Filtro laplaciano-gaussiano
[#img-sunset]
[caption="Figure 14: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/laplaciano%20de%20gaussiano.jpg.jpg?raw=true[Sunset,300,300]



== Unidade 2

=== Filtro homomórfico

Tendo como base o programa exemplos/dft.cpp, foram feitas algumas alterações. O filtro utilizado é um filtro homomórfico, que é caracterizado pela equação abaixo, no lugar do filtro passa-baixas. São adicionados sliders para uma melhor determinação dos parâmetros de entrada para esse filtro e, a cada modificação de um valor dos sliders, é executado o mesmo algortimo do programa exemplo.cpp, porém utilizando uma função que aplica o filtro homomórfico.

.Equação do filtro homomórfico
[#img-sunset]
[caption="Figure 15: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/homomorficofiltro.png?raw=true[Sunset,488,74]

 
 
 
 
 O programa recebe uma imagem em tons de cinza como entrada e logo depois, ela é mostrada na tela. Após o usuário apertar uma tecla, começa-se a preparação para a aplicação do filtro, obtendo-se, primeiramente, as dimensões ótimas pra dft. A primeira operação que é feita na imagem é o padding que adequará as dimensões da imagem para a aplicação da dft. Após isso, é somado o valor 1 para todos os pixels para poder aplicar a função logarítmica natural. Após aplicar a função logarítmica, realiza-se a dft. Realiza-se uma troca de regiões no domínio da frequência logo em seguida para facilitar a aplicação do filtro, deixando as regiões de baixa frequência no centro. A matriz resultante dessa última operação ficará guardada no objeto complexImage e assim, quando o usuário fizer alterações nos parâmetros do filtro através de barras de rolagem, não será necessário refazer todas as operações anteriores. O usuário poderá modificar, através da barra de rolagem, quatro parâmetros. São eles: yh(ganho das regiões superiores a frequência de corte), yl(ganho das regiões inferiores a frequência de corte), d0(frequência de corte) e c(constante que multiplica o expoente da função exponencial e que influencia na região de transição). Após a aplicação do filtro com os parâmetros desejados, um nova troca de regiões será realizada e a dft inversa será aplicada. Será pego só a parte real do resultado. Depois, será aplicada uma função exponencial e o resultado obtido será normalizado para sua exibição na tela. E quando o usuário apertar uma tecla, novamente, o programa será encerrado.
 
 
 
[source,cpp]
-----------------
#include <iostream>
#include <opencv2/opencv.hpp>
#include <opencv2/imgproc/imgproc.hpp>

#define RADIUS 20

using namespace cv;
using namespace std;

double gama_h;
int gama_h_slider = 0;
int gama_h_slider_max = 100;

double gama_l;
int gama_l_slider = 0;
int gama_l_slider_max = 100;

double c;
int c_slider = 0;
int c_slider_max = 100;

double d0;
int d0_slider = 0;
int d0_slider_max = 100;

char TrackbarName[50];

void on_trackbar_gama_h(int, void*){
 gama_h = (double) gama_h_slider ;
}

void on_trackbar_gama_l(int, void*){
 gama_l = (double) gama_l_slider  ;
}

void on_trackbar_c(int, void*){
 c = (double) c_slider  ;
}

void on_trackbar_d0(int, void*){
 d0 = (double) d0_slider ;
}

Mat ObterFiltroHomomorfico(int M, int N){
  Mat H = Mat(M, N, CV_32F), filter;
  for(int i=0; i<M; i++){
    for(int j=0; j<N; j++){
        H.at<float> (i,j) = (gama_h-gama_l)*(1.0-exp(-1.0*(float)c*((((float)i-M/2.0)*((float)i-M/2.0) + ((float)j-N/2.0)*((float)j-N/2.0))/(d0*d0))))+ gama_l;
    }
  }
  Mat comps[]= {H, H};
  merge(comps, 2, filter);
  return filter;
}

// troca os quadrantes da imagem da DFT
void deslocaDFT(Mat& image ){
  Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para
  // evitar cópias de tamanho desigual
  image = image(Rect(0, 0, image.cols & -2, image.rows & -2));
  int cx = image.cols/2;
  int cy = image.rows/2;

  // reorganiza os quadrantes da transformada
  // A B   ->  D C
  // C D       B A
  A = image(Rect(0, 0, cx, cy));
  B = image(Rect(cx, 0, cx, cy));
  C = image(Rect(0, cy, cx, cy));
  D = image(Rect(cx, cy, cx, cy));

  // A <-> D
  A.copyTo(tmp);  D.copyTo(A);  tmp.copyTo(D);

  // C <-> B
  C.copyTo(tmp);  B.copyTo(C);  tmp.copyTo(B);
}

int main(int , char** argv){
  VideoCapture cap;
  Mat imaginaryInput, complexImage, multsp;
  Mat padded, filter, mag;
  Mat image, imagegray, tmp;
  Mat_<float> realInput, zeros;
  vector<Mat> planos;
  char key;
  namedWindow("original",1);

  sprintf( TrackbarName, "Gama H: ");
    createTrackbar( TrackbarName, "original",
            &gama_h_slider,
            gama_h_slider_max,
            on_trackbar_gama_h );
    on_trackbar_gama_h(gama_h_slider, 0 );

  sprintf( TrackbarName, "Gama L: ");
    createTrackbar( TrackbarName, "original",
            &gama_l_slider,
            gama_l_slider_max,
            on_trackbar_gama_l );
    on_trackbar_gama_l(gama_l_slider, 0 );

  sprintf( TrackbarName, "C: ");
    createTrackbar( TrackbarName, "original",
            &c_slider,
            c_slider_max,
            on_trackbar_c );
    on_trackbar_c(c_slider, 0 );

  sprintf( TrackbarName, "D0: ");
    createTrackbar( TrackbarName, "original",
            &d0_slider,
            d0_slider_max,
            on_trackbar_d0 );
    on_trackbar_d0(d0_slider, 0 );

  // valores ideais dos tamanhos da imagem
  // para calculo da DFT
  int dft_M, dft_N;

  image = imread(argv[1]);
  // identifica os tamanhos otimos para
  // calculo do FFT
  dft_M = getOptimalDFTSize(image.rows);
  dft_N = getOptimalDFTSize(image.cols);

  // realiza o padding da imagem
  copyMakeBorder(image, padded, 0,
                 dft_M - image.rows, 0,
                 dft_N - image.cols,
                 BORDER_CONSTANT, Scalar::all(0));

  // parte imaginaria da matriz complexa (preenchida com zeros)
  zeros = Mat_<float>::zeros(padded.size());

  // prepara a matriz complexa para ser preenchida
  complexImage = Mat(padded.size(), CV_32FC2, Scalar(0));

  // a função de transferência (filtro frequencial) deve ter o
  // mesmo tamanho e tipo da matriz complexa
  filter = complexImage.clone();

  // cria uma matriz temporária para criar as componentes real
  // e imaginaria do filtro ideal
  tmp = Mat(dft_M, dft_N, CV_32F);

  

  // cria a matriz com as componentes do filtro e junta
  // ambas em uma matriz multicanal complexa
  Mat comps[]= {tmp, tmp};
  merge(comps, 2, filter);

  for(;;){
    //cap >> image;
    image = imread(argv[1]);
    cvtColor(image, imagegray, CV_BGR2GRAY);
    imshow("original", imagegray);

    // realiza o padding da imagem
    copyMakeBorder(imagegray, padded, 0,
                   dft_M - image.rows, 0,
                   dft_N - image.cols,
                   BORDER_CONSTANT, Scalar::all(0));

    // limpa o array de matrizes que vao compor a
    // imagem complexa
    planos.clear();
    // cria a compoente real
    realInput = Mat_<float>(padded);
    // insere as duas componentes no array de matrizes
    planos.push_back(realInput);
    planos.push_back(zeros);

    // combina o array de matrizes em uma unica
    // componente complexa
    merge(planos, complexImage);

    // calcula o dft
    dft(complexImage, complexImage);

    // realiza a troca de quadrantes
    deslocaDFT(complexImage);

    filter = ObterFiltroHomomorfico(dft_M, dft_N);

    // aplica o filtro frequencial
    mulSpectrums(complexImage,filter,complexImage,0);

    // limpa o array de planos
    planos.clear();
    // separa as partes real e imaginaria para modifica-las
    split(complexImage, planos);

    // recompoe os planos em uma unica matriz complexa
    merge(planos, complexImage);

    // troca novamente os quadrantes
    deslocaDFT(complexImage);

    // calcula a DFT inversa
    idft(complexImage, complexImage);

    // limpa o array de planos
    planos.clear();

    // separa as partes real e imaginaria da
    // imagem filtrada
    split(complexImage, planos);

    // normaliza a parte real para exibicao
    normalize(planos[0], planos[0], 0, 1, CV_MINMAX);
    imshow("filtrada", planos[0]);

    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    if (key == 99){
      imwrite("filtrada.png", planos[0]);      
      imwrite("original.png", imagegray);
    }
  }
  return 0;
}
}

-----------------

.Lado a lado, imagem original e resultado do filtro
[#img-sunset]
[caption="Figure 16: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/it.png?raw=true[Sunset,720,550]


=== Canny e o pontilhismo

O problema consiste na utilização das bordas encontradas pelo algoritmo de Canny para o melhoramento da técnica do pontilhismo. Inicialmente foi aplicado na imagem o processo de pontilhismo, e logo apos a imagem bruta passou por algumas iterações do filtro de Canny, para que fosse possível delimitar suas bordas. Em cada uma das iterações o limiar do filtro é alterado com a intenção de obter uma imagem com menos bordas. Para as bordas ficarem mais destacadas foi necessário percorrer a imagem filtrada e desenhar um círculo em cada pixel que possuísse um tom de cinza maior que zero. 
 
 
 
[source,cpp]
-----------------
  #include <iostream>
  #include <opencv2/opencv.hpp>
  #include <fstream>
  #include <iomanip>
  #include <vector>
  #include <algorithm>
  #include <numeric>
  #include <ctime>
  #include <cstdlib>

  using namespace std;
  using namespace cv;


  #define STEP 5
  #define JITTER 3
  #define RAIO 2

  int main(int argc, char** argv){
  Mat Original, borderOriginalImage;
  Mat Pontilhismo;
  int x, y, width, height, gray;
  
  vector<int> yrange;
  vector<int> xrange;

  srand(time(0));

  Original= imread("zico.jpg" ,CV_LOAD_IMAGE_GRAYSCALE);

  width = Original.size().width;
  height = Original.size().height;
  xrange.resize(height/STEP);
  yrange.resize(width/STEP);
  iota(xrange.begin(), xrange.end(), 0);
  iota(yrange.begin(), yrange.end(), 0);

  for(uint i=0; i<xrange.size(); i++){
    xrange[i]= xrange[i]*STEP+STEP/2;
  }

  for(uint i=0; i<yrange.size(); i++){
    yrange[i]= yrange[i]*STEP+STEP/2;
  }

  Original.copyTo(Pontilhismo);

  //Executa o pontilhismo;
  for(auto i : xrange){
    random_shuffle(yrange.begin(), yrange.end());
    for(auto j : yrange){
      x = i+rand()%(2*JITTER)-JITTER+1;
      y = j+rand()%(2*JITTER)-JITTER+1;
      gray = Original.at<uchar>(x,y);
      circle(Pontilhismo, cv::Point(y,x), RAIO, CV_RGB(gray,gray,gray), -1, CV_AA);
    }
  }

  imshow("Imagem Pontilhista", Pontilhismo);
  imwrite("imagemComPontilhismo.jpg", Pontilhismo);

   //Aplica Canny
   for(int z=0; z<5; z++){
     Canny(Original, borderOriginalImage, 10*z, 50*z);
     int raio = 10-z;

     for(int i=0; i<height; i++ ){
        for(int j=0; j<width; j++){
           if(borderOriginalImage.at<uchar>(i,j) == 255){
              gray = Original.at<uchar>(i,j);
              circle(Pontilhismo, cv::Point(j,i), raio, CV_RGB(gray,gray,gray), -1, CV_AA);
             }
        }
    }


  }
  imshow("Pontilhismo", Pontilhismo);
  imwrite("imagemComPontilhismo.jpg", Pontilhismo);

   waitKey();
  return 0;
}

-----------------

.Imagem original
[#img-sunset]
[caption="Figure 17: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/zico.jpg?raw=true[Sunset,622,350]

.Imagem pontilhista com raio 5
[#img-sunset]
[caption="Figure 18: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/imagem%20pontilhista.png?raw=true[Sunset,622,350]

.Imagem pontilhista com raio 3
[#img-sunset]
[caption="Figure 19: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/raio%203%20pontilhismo.png?raw=true[Sunset,622,350]

.Resultado final, utilizando como base a imagem pontilhista com raio 5
[#img-sunset]
[caption="Figure 20: "]
image::https://github.com/leoaugustoam/leoaugustoam.github.io/blob/master/imagens/final.png?raw=true[Sunset,622,350]
